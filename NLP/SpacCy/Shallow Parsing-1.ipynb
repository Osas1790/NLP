{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Parsing\n",
    "Shallow parsing, also known as chunking or light parsing, is a process in Natural Language Processing (NLP) that identifies the constituents (parts of speech) of sentences and links them into higher-order units that are less than the sentence but more than individual words. Unlike full parsing, which provides a deep grammatical analysis of a sentence, shallow parsing focuses on identifying phrases (such as noun phrases, verb phrases) without diving into detailed syntactic relationships.\n",
    "\n",
    "Shallow parsing, or chunking, is the process of extracting phrases from unstructured text. This involves chunking groups of adjacent tokens into phrases on the basis of their POS tags. There are some standard well-known chunks such as noun phrases, verb phrases, and prepositional phrases.\n",
    "\n",
    "Key aspects of shallow parsing:\n",
    "\n",
    "- Phrase Identification: Shallow parsing aims to identify phrases in a sentence. For example, in the sentence \"The quick brown fox jumps over the lazy dog\", a shallow parser might identify \"The quick brown fox\" as a noun phrase and \"jumps over\" as a verb phrase.\n",
    "- Simpler than Full Parsing: Shallow parsing is less complex than full parsing (dependency or constituency parsing). It doesn't provide a full syntactic structure but gives useful information about the general structure of sentences.\n",
    "- Use of POS Tags: Shallow parsing typically builds upon the results of part-of-speech tagging. It uses these POS tags to group words into phrases.\n",
    "- Applications: Shallow parsing is useful in various NLP tasks such as information extraction, question answering, and text summarization where detailed syntactic parsing might be unnecessary.\n",
    "- Chunking: In shallow parsing, chunking is the process of extracting phrases. A chunk is a collection of words sequentially tagged by part-of-speech taggers. Rules or machine learning algorithms can define how words are grouped into chunks.\n",
    "- Named Entity Recognition (NER): Although NER is a related task, it's more specific than shallow parsing. NER focuses on identifying and classifying named entities (like names of people, organizations, locations) in the text.\n",
    "Shallow parsing is a balance between the complexity and depth of full parsing and the simplicity and speed of basic POS tagging, making it a valuable tool in many NLP applications.\n",
    "\n",
    "\n",
    "## Noun Phrase Detection\n",
    "A noun phrase is a phrase that has a noun as its head. It could also include other kinds of words, such as adjectives, ordinals, and determiners. Noun phrases are useful for explaining the context of the sentence. They help you understand what the sentence is about.\n",
    "\n",
    "spaCy has the property .noun_chunks on the Doc object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a developer conference\n",
      "21 July\n",
      "London\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "conference_text = \"There is a developer conference happening on 21 July 2019 in London.\"\n",
    "conference_doc = nlp(conference_text)\n",
    "\n",
    "# Extract Noun Phrases\n",
    "for chunk in conference_doc.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verb Phrase Detection\n",
    "A verb phrase is a syntactic unit composed of at least one verb. This verb can be joined by other chunks, such as noun phrases. Verb phrases are useful for understanding the actions that nouns are involved in.\n",
    "\n",
    "spaCy has no built-in functionality to extract verb phrases, so youâ€™ll need a library called textacy. You can use pip to install textacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will introduce\n",
      "The talk\n",
      "reader\n",
      "use cases\n",
      "Natural Language Processing\n",
      "Fintech\n",
      "use\n",
      "interesting examples\n",
      "the way\n"
     ]
    }
   ],
   "source": [
    "import textacy\n",
    "\n",
    "about_talk_text = (\n",
    "    \"The talk will introduce reader about use\"\n",
    "    \" cases of Natural Language Processing in\"\n",
    "    \" Fintech, making use of\"\n",
    "    \" interesting examples along the way.\"\n",
    ")\n",
    "\n",
    "patterns = [{\"POS\": \"AUX\"}, {\"POS\": \"VERB\"}]\n",
    "about_talk_doc = textacy.make_spacy_doc(about_talk_text, lang=\"en_core_web_sm\")\n",
    "verb_phrases = textacy.extract.token_matches(about_talk_doc, patterns=patterns)\n",
    "\n",
    "# Print all verb phrases\n",
    "for chunk in verb_phrases:\n",
    "    print(chunk.text)\n",
    "\n",
    "\n",
    "# Extract noun phrase to explain what nouns are involved\n",
    "for chunk in about_talk_doc.noun_chunks:\n",
    "    print(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
