{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENTENCE DETECTION\n",
    "Sentence detection is the process of locating where sentences start and end in a given text. This allows you to you divide a text into linguistically meaningful units. You’ll use these units when you’re processing your text to perform tasks such as part-of-speech (POS) tagging and named-entity recognition. https://en.wikipedia.org/wiki/Part-of-speech_tagging.\n",
    "In spacy, the .sents property is used to extract sentences from the doc object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "about_txt = (\n",
    "    \"spaCy is an open-source software library for advanced Natural Language Processing (NLP) in Python\"\n",
    "    \"It's designed to be fast, efficient, and highly accessible, making it a popular choice for building NLP applications\"\n",
    "    \"spaCy excels in tasks like part-of-speech tagging, named entity recognition, dependency parsing, and more\"\n",
    "    \"It supports multiple languages and offers pre-trained models for various NLP tasks\"\n",
    "    \"optimized for both performance and accuracy.Its design is geared towards practical\"\n",
    "    \"real-world applications and it's widely used in industry and academia for building NLP pipelines and applications.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "about_txt = nlp(about_txt)\n",
    "# print(about_txt.ents)\n",
    "sentences = list(about_txt.sents)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy is an open-...\n",
      "Its design is geared towards...\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences:\n",
    "    print(f\"{sent[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize sentence detection behavior by using custom delimiters\n",
    "ellipsis_txt = (\n",
    "    \"Gus, can you, ... never mind, I forgot\"\n",
    "    \" what I was saying. So, do you think\"\n",
    "    \" we should ...\"\n",
    ")\n",
    "\n",
    "from spacy.language import Language\n",
    "\n",
    "\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \"...\":\n",
    "            doc[token.i + 1].is_sent_start = True\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus, can you, ...\n",
      "never mind, I forgot what I was saying.\n",
      "So, do you think we should ...\n"
     ]
    }
   ],
   "source": [
    "custom_nlp = spacy.load(\"en_core_web_sm\")\n",
    "custom_nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")\n",
    "custom_ellipsis_doc = custom_nlp(ellipsis_txt)\n",
    "custom_ellipsis_sentences = list(custom_ellipsis_doc.sents)\n",
    "for sentence in custom_ellipsis_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
